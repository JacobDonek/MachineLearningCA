{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e60e002d-a69e-4c1c-aa57-3b936940433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Data Import + Basic Cleaning + Username/Date Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b4b189b-47b6-4397-ab78-1416d363d88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               link  \\\n",
      "0   0  https://twitter.com/HackneyPSC/status/17274436...   \n",
      "1   1  https://twitter.com/cherrysattitude/status/172...   \n",
      "2   2  https://twitter.com/diamoundgirls2/status/1710...   \n",
      "3   3  https://twitter.com/mmtchi/status/172764634165...   \n",
      "4   4  https://twitter.com/NoahIeeNG/status/172744319...   \n",
      "\n",
      "                                                text              date  likes  \\\n",
      "0  A statement from psychoanalytic activists:  Th...  11/22/2023 21:47      0   \n",
      "1                        bak bak bak bak doyamadƒ±nƒ±z  11/22/2023 15:27    443   \n",
      "2  Check out üèí 35 + different ERIK KARLSSON cards...    10/7/2023 7:15      0   \n",
      "3  Il s'en passe des trucs pendant qu'on vous ori...  11/23/2023 11:12    381   \n",
      "4  AW OKAY.. WELL THATS COOL, IM SURE PAL WILL AP...  11/22/2023 21:45      0   \n",
      "\n",
      "   comments  \n",
      "0         0  \n",
      "1         9  \n",
      "2         0  \n",
      "3        44  \n",
      "4         0  \n"
     ]
    }
   ],
   "source": [
    "#step 1 - import the pandas library to work with the csv dataset, numpy for numerical operations, \n",
    "#regular expressions for pattern matching, emoji for emoji-related features and Standard Scaler for feature scaling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#step 2 - load the csv file with tweets\n",
    "df = pd.read_csv(\"Tweets.csv\")\n",
    "\n",
    "#step 3 - show the first 5 rows to preview the data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9720cda6-f5d5-4161-8327-6181076de624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4 - extract usernames from the tweet link\n",
    "#the username is always the fourth part after the third \"/\"\n",
    "def extract_username(link):\n",
    "    try:\n",
    "        return link.split(\"/\")[3] #this gets the username\n",
    "    except:\n",
    "        return None #if the link is missing or broken, this returns nothing\n",
    "\n",
    "df['username'] = df['link'].apply(extract_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ac5e333-32c5-4c80-9c8f-34e4ee2d2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 5 - convert the 'date' column to datetime format needed for timeline features \n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce') #errors='coerce' deals with bad data\n",
    "\n",
    "#step 6 - drop empty rows\n",
    "df.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e2510023-57a5-4233-88e0-8e7402c84e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15498 entries, 0 to 15497\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   id        15498 non-null  int64         \n",
      " 1   link      15498 non-null  object        \n",
      " 2   text      15470 non-null  object        \n",
      " 3   date      15498 non-null  datetime64[ns]\n",
      " 4   likes     15498 non-null  int64         \n",
      " 5   comments  15498 non-null  int64         \n",
      " 6   username  15498 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(3), object(3)\n",
      "memory usage: 847.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#step 7 - print basic info to see how many columns and rows are present\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b3f15c69-3094-46b2-beaa-0b97a4a611e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "73ab3b37-8fa9-4726-86e2-3bea50c24eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 - count how many tweets each user posted\n",
    "tweet_count = df['username'].value_counts().rename_axis('username').reset_index(name='tweet_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39608022-8c27-4c1a-b78f-55aedcea6943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2 - sort tweets by user and date to calculate the gap between tweets\n",
    "df_sorted = df.sort_values(by=['username', 'date'])\n",
    "df_sorted['time_difference'] = df_sorted.groupby('username')['date'].diff().dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1209eb06-2683-4208-81aa-00d5a6139ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3 - calculolate average time between tweets for each user in  minutes\n",
    "average_time_between =  df_sorted.groupby('username')['time_difference'].mean().fillna(0)\n",
    "average_time_between_minutes = (average_time_between / 60).rename('average_time_between_tweets_minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9829bb50-b15d-4396-a0c2-55979e265b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4 - check how many tweets are written in 50% >= all caps\n",
    "def is_majority_all_caps(text):\n",
    "    try:\n",
    "        words = text. split()\n",
    "        if not words:\n",
    "            return False\n",
    "        return sum(words.isupper() for word in words) / len(words) > 0.5\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "percentage_all_caps = df.groupby('username')['text'].apply(\n",
    "    lambda tweets: np.mean([is_majority_all_caps(t) for t in tweets])\n",
    ").rename('percentage_of_tweets_with_all_caps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f43e4a9d-4b69-4115-9ce6-175c20131832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 5 - count average number of emojis in each tweet\n",
    "def count_emojis(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0 \n",
    "    return sum (1 for c in text if c in emoji.EMOJI_DATA)\n",
    "\n",
    "average_emoji_count = df.groupby('username')['text'].apply(\n",
    "    lambda tweets: np.mean([count_emojis(t) for t in tweets])\n",
    ").rename('average_emoji_count_per_tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f688e951-40b7-4c2f-bf7d-398fac00171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 6 - track emotionally intense language using a basic list of trigger words\n",
    "emotional_words = [\"attack\", \"hate\", \"furious\", \"angry\", \"kill\", \"rage\", \"disgust\", \"traitor\", \"destroy\", \"explode\"]\n",
    "\n",
    "def count_emotional_words(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return sum(word in emotional_words for word in words)\n",
    "\n",
    "average_emotion_words = df.groupby('username')['text'].apply(\n",
    "    lambda tweets: np.mean([count_emotional_words(t) for t in tweets])\n",
    ").rename('average_emotionally_charged_words_per_tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "70341b2e-8edb-41b9-a7aa-c5c287a0fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 7 - calculate tweet length average per user\n",
    "average_tweet_length = df.groupby('username')['text'].apply(\n",
    "    lambda tweets: np.mean([len(str(t)) for t in tweets])\n",
    ").rename('average_tweet_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83e24a95-2fef-4ea0-a6c1-5da8f573b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 8 - count average number of hashtags per tweet \n",
    "def count_hashtags(text):\n",
    "    return len(re.findall(r'#\\w+', str(text)))\n",
    "\n",
    "average_hashtags = df.groupby('username')['text'].apply(\n",
    "    lambda tweets: np.mean([count_hashtags(t) for t in tweets])\n",
    ").rename('average_hashtag_frequency_per_tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b11c780-cde5-4e24-adf6-789ac9a83ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 9 - set tweet count index to match others\n",
    "tweet_count = tweet_count.set_index('username')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0580dfad-ccda-400a-bdfa-e0a209be0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 10 - combine all features coded until now into one dataset\n",
    "feature_matrix = pd.concat([\n",
    "    tweet_count,\n",
    "    average_time_between_minutes,\n",
    "    percentage_all_caps,\n",
    "    average_emoji_count,\n",
    "    average_emotion_words,\n",
    "    average_tweet_length,\n",
    "    average_hashtags\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ae9f85b-ded7-4bc1-8034-bbaa40a778cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 tweet_count  average_time_between_tweets_minutes  \\\n",
      "username                                                            \n",
      "Novytique                 84                            45.156627   \n",
      "salusalemchalom           48                             5.851064   \n",
      "Kuwait_KW01               38                           102.054054   \n",
      "diamoundgirls2            37                            27.305556   \n",
      "AvivaKlompas              31                           958.433333   \n",
      "\n",
      "                 percentage_of_tweets_with_all_caps  \\\n",
      "username                                              \n",
      "Novytique                                       0.0   \n",
      "salusalemchalom                                 0.0   \n",
      "Kuwait_KW01                                     0.0   \n",
      "diamoundgirls2                                  0.0   \n",
      "AvivaKlompas                                    0.0   \n",
      "\n",
      "                 average_emoji_count_per_tweet  \\\n",
      "username                                         \n",
      "Novytique                             0.000000   \n",
      "salusalemchalom                       0.000000   \n",
      "Kuwait_KW01                           0.210526   \n",
      "diamoundgirls2                        1.081081   \n",
      "AvivaKlompas                          0.419355   \n",
      "\n",
      "                 average_emotionally_charged_words_per_tweet  \\\n",
      "username                                                       \n",
      "Novytique                                           0.000000   \n",
      "salusalemchalom                                     0.000000   \n",
      "Kuwait_KW01                                         0.000000   \n",
      "diamoundgirls2                                      0.000000   \n",
      "AvivaKlompas                                        0.096774   \n",
      "\n",
      "                 average_tweet_length  average_hashtag_frequency_per_tweet  \n",
      "username                                                                    \n",
      "Novytique                  239.678571                            10.000000  \n",
      "salusalemchalom            190.041667                             0.000000  \n",
      "Kuwait_KW01                172.447368                             4.394737  \n",
      "diamoundgirls2             407.675676                             4.081081  \n",
      "AvivaKlompas               286.354839                             0.064516  \n"
     ]
    }
   ],
   "source": [
    "#step 11 - chech the final result\n",
    "print(feature_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52e22102-a4ab-4589-8d96-daed3e2a0c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7042bd16-babb-4d8e-a8de-42ba573628a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 - use StandardScaler to normalise all values so they are similar in range\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9af9d299-e49c-491a-8a5d-c518aa17ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2 - convert back to dataframe so we can still see column names\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=feature_matrix.columns, index=feature_matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "94070868-496c-48cc-a6e7-0700c9343d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 tweet_count  average_time_between_tweets_minutes  \\\n",
      "username                                                            \n",
      "Novytique          46.443893                            -0.038475   \n",
      "salusalemchalom    26.189500                            -0.040856   \n",
      "Kuwait_KW01        20.563280                            -0.035029   \n",
      "diamoundgirls2     20.000658                            -0.039557   \n",
      "AvivaKlompas       16.624925                             0.016839   \n",
      "\n",
      "                 percentage_of_tweets_with_all_caps  \\\n",
      "username                                              \n",
      "Novytique                                       0.0   \n",
      "salusalemchalom                                 0.0   \n",
      "Kuwait_KW01                                     0.0   \n",
      "diamoundgirls2                                  0.0   \n",
      "AvivaKlompas                                    0.0   \n",
      "\n",
      "                 average_emoji_count_per_tweet  \\\n",
      "username                                         \n",
      "Novytique                            -0.157956   \n",
      "salusalemchalom                      -0.157956   \n",
      "Kuwait_KW01                          -0.037306   \n",
      "diamoundgirls2                        0.461595   \n",
      "AvivaKlompas                          0.082370   \n",
      "\n",
      "                 average_emotionally_charged_words_per_tweet  \\\n",
      "username                                                       \n",
      "Novytique                                          -0.229234   \n",
      "salusalemchalom                                    -0.229234   \n",
      "Kuwait_KW01                                        -0.229234   \n",
      "diamoundgirls2                                     -0.229234   \n",
      "AvivaKlompas                                        0.121806   \n",
      "\n",
      "                 average_tweet_length  average_hashtag_frequency_per_tweet  \n",
      "username                                                                    \n",
      "Novytique                    0.165628                             5.884834  \n",
      "salusalemchalom             -0.000256                            -0.276957  \n",
      "Kuwait_KW01                 -0.059056                             2.430988  \n",
      "diamoundgirls2               0.727068                             2.237720  \n",
      "AvivaKlompas                 0.321618                            -0.237203  \n"
     ]
    }
   ],
   "source": [
    "#step 3 - check the final scaled values\n",
    "print(scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3fe2f3-69e4-4729-a527-5c4efe2cb37d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
